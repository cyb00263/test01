{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dqn_tictactoe.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNdS/YIZ1JbmPs/KH3QmSHF",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cyb00263/test01/blob/main/dqn_tictactoe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpGmWbFCkYt0",
        "outputId": "020de12a-9e9a-4513-d6c4-bde953c8779d"
      },
      "source": [
        "#installing dependencies\r\n",
        "!apt-get -qq -y install libcusparse8.0 libnvrtc8.0 libnvtoolsext1 > /dev/null\r\n",
        "!ln -snf /usr/lib/x86_64-linux-gnu/libnvrtc-builtins.so.8.0 /usr/lib/x86_64-linux-gnu/libnvrtc-builtins.so\r\n",
        "!apt-get -qq -y install xvfb freeglut3-dev ffmpeg> /dev/null\r\n",
        "\r\n",
        "!pip -q install gym\r\n",
        "!pip -q install pyglet\r\n",
        "!pip -q install pyopengl\r\n",
        "!pip -q install pyvirtualdisplay\r\n",
        "\r\n",
        "# Start virtual display\r\n",
        "from pyvirtualdisplay import Display\r\n",
        "display = Display(visible=0, size=(1024, 768))\r\n",
        "display.start()\r\n",
        "import os\r\n",
        "#os.environ[\"DISPLAY\"] = \":\" + str(display.display) + \".\" + str(display.screen)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E: Unable to locate package libcusparse8.0\n",
            "E: Couldn't find any package by glob 'libcusparse8.0'\n",
            "E: Couldn't find any package by regex 'libcusparse8.0'\n",
            "E: Unable to locate package libnvrtc8.0\n",
            "E: Couldn't find any package by glob 'libnvrtc8.0'\n",
            "E: Couldn't find any package by regex 'libnvrtc8.0'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eFyap0zkYcN",
        "outputId": "daa21a93-6247-4cec-84bf-97e9b7dfe504"
      },
      "source": [
        "!pip install tensorflow==1.14\r\n",
        "!pip install keras==2.2.4\r\n",
        "!pip install keras-rl==0.4.2"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==1.14 in /usr/local/lib/python3.6/dist-packages (1.14.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.32.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.8.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.15.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.0.8)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.14.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.14.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (3.12.4)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.12.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.10.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.19.4)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.36.2)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.3.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.1.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14) (2.10.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (51.0.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.3.3)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.7.4.3)\n",
            "Requirement already satisfied: keras==2.2.4 in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.19.4)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.1.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (2.10.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.15.0)\n",
            "Requirement already satisfied: keras-rl==0.4.2 in /usr/local/lib/python3.6/dist-packages (0.4.2)\n",
            "Requirement already satisfied: keras>=2.0.7 in /usr/local/lib/python3.6/dist-packages (from keras-rl==0.4.2) (2.2.4)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.7->keras-rl==0.4.2) (1.0.8)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.7->keras-rl==0.4.2) (3.13)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.7->keras-rl==0.4.2) (1.15.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.7->keras-rl==0.4.2) (1.4.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.7->keras-rl==0.4.2) (1.1.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.7->keras-rl==0.4.2) (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras>=2.0.7->keras-rl==0.4.2) (1.19.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qr4Ch4cHsTOp"
      },
      "source": [
        "import math\r\n",
        "import gym\r\n",
        "from gym import spaces, logger\r\n",
        "from gym.utils import seeding\r\n",
        "import numpy as np\r\n",
        "import copy\r\n",
        "import random\r\n",
        "\r\n",
        "class TicTacToeEnv(gym.core.Env):\r\n",
        "    def __init__(self):\r\n",
        "        self.n_action = 9\r\n",
        "        self.board = [0] * self.n_action\r\n",
        "        self.action_space = gym.spaces.Discrete(self.n_action) # actionの取りうる値\r\n",
        "        self.observation_space = gym.spaces.Box(low=-1, high =1, shape=(self.n_action,)) \r\n",
        "        self.result = []\r\n",
        "\r\n",
        "    def step(self, action):\r\n",
        "      self.board, end_flg, reward = self.get_input(self.board, action)\r\n",
        "      done = end_flg\r\n",
        "      info = {}\r\n",
        "\r\n",
        "      return self.board, reward, done, info\r\n",
        "\r\n",
        "    def get_input(self, board, action):\r\n",
        "      end_flg = 0\r\n",
        "      reward = 0\r\n",
        "      #AI#\r\n",
        "      space = [i for i, x in enumerate(board) if x == 0 ]\r\n",
        "      if action in space:\r\n",
        "        flg = 1\r\n",
        "        board[action] = flg\r\n",
        "        end_flg = self.judge(board,flg)\r\n",
        "        if end_flg == 1:\r\n",
        "          reward = 1\r\n",
        "          self.result.append(reward)\r\n",
        "      #乱数#\r\n",
        "        else:\r\n",
        "          space = [i for i, x in enumerate(board) if x == 0 ]\r\n",
        "          ransu = int(random.choice(space))\r\n",
        "          flg = -1\r\n",
        "          board[ransu] = flg\r\n",
        "          end_flg = self.judge(board,flg)\r\n",
        "          if end_flg == 1:\r\n",
        "            reward = -1\r\n",
        "            self.result.append(reward)\r\n",
        "      else:\r\n",
        "        end_flg = 1\r\n",
        "        reward = -1\r\n",
        "        self.result.append(reward)\r\n",
        "\r\n",
        "      return board, end_flg, reward\r\n",
        "\r\n",
        "    def judge(self, board, flg):\r\n",
        "      end_flg = 0\r\n",
        "      first_list = [0, 3, 6, 0, 1, 2, 0, 2]\r\n",
        "      second_list = [1, 4, 7, 3, 4, 5, 4, 4]\r\n",
        "      third_list = [2, 5, 8, 6, 7, 8, 8, 6]\r\n",
        "      for first, second, third in zip(first_list, second_list, third_list):\r\n",
        "        if board[first] ==flg and board[first] == board[second] and board[first] == board[third]:\r\n",
        "          end_flg = 1\r\n",
        "          break\r\n",
        "      space = [i for i, x in enumerate(board) if x == 0 ]\r\n",
        "      if len(space) == 0:\r\n",
        "        end_flg = 1\r\n",
        "        reward = -1\r\n",
        "\r\n",
        "      return end_flg\r\n",
        "    \r\n",
        "    def reset(self):\r\n",
        "        self.board = [0] * self.n_action\r\n",
        "        return self.board\r\n",
        "\r\n",
        "    def render(self, mode):\r\n",
        "        pass\r\n",
        "\r\n",
        "    def close(self):\r\n",
        "        pass\r\n",
        "\r\n",
        "    def seed(self):\r\n",
        "        pass"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tD_BrfZckXPv",
        "outputId": "7ab709e1-200f-4da1-ecd2-a633fe2c04f4"
      },
      "source": [
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense, Activation, Flatten\r\n",
        "from keras.optimizers import Adam\r\n",
        "from rl.agents.dqn import DQNAgent\r\n",
        "from rl.policy import BoltzmannQPolicy\r\n",
        "from rl.memory import SequentialMemory\r\n",
        "\r\n",
        "env = TicTacToeEnv()\r\n",
        "n_action = 9\r\n",
        "\r\n",
        "# ニューラルネットワークの構造を定義\r\n",
        "model = Sequential()\r\n",
        "model.add(Flatten(input_shape=(1,) + env.observation_space.shape))\r\n",
        "model.add(Dense(128))\r\n",
        "model.add(Activation('relu'))\r\n",
        "model.add(Dense(n_action))\r\n",
        "model.add(Activation('linear'))\r\n",
        "print(model.summary()) # モデルの定義をコンソールに出力\r\n",
        " \r\n",
        "# モデルのコンパイル\r\n",
        "memory = SequentialMemory(limit=50000, window_length=1)\r\n",
        "policy = BoltzmannQPolicy(tau=1.)\r\n",
        "dqn = DQNAgent(model=model, nb_actions=n_action, memory=memory, nb_steps_warmup=50, target_model_update=1e-2, policy=policy)\r\n",
        "dqn.compile(Adam(lr=1e-3), metrics=['mae'])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_1 (Flatten)          (None, 9)                 0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               1280      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 9)                 1161      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 9)                 0         \n",
            "=================================================================\n",
            "Total params: 2,441\n",
            "Trainable params: 2,441\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 619
        },
        "id": "TX9nrSUb65Rk",
        "outputId": "44b6e690-53ed-455a-f46a-81d005e0e89a"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "# fit の結果を取得しておく\r\n",
        "history = dqn.fit(env, nb_steps=50000, visualize=False, verbose=1)\r\n",
        "\r\n",
        "dqn.save_weights('dqn_{}_weights.h5f'.format(\"TicTacToe\"), overwrite=True)\r\n",
        "\r\n",
        "# 結果を表示\r\n",
        "plt.subplot(2,1,1)\r\n",
        "plt.plot(history.history[\"nb_episode_steps\"])\r\n",
        "plt.ylabel(\"step\")\r\n",
        "\r\n",
        "plt.subplot(2,1,2)\r\n",
        "plt.plot(history.history[\"episode_reward\"])\r\n",
        "plt.xlabel(\"episode\")\r\n",
        "plt.ylabel(\"reward\")\r\n",
        "\r\n",
        "plt.show()  # windowが表示されます。"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training for 50000 steps ...\n",
            "Interval 1 (0 steps performed)\n",
            "10000/10000 [==============================] - 52s 5ms/step - reward: -0.0971\n",
            "2693 episodes - episode_reward: -0.361 [-1.000, 1.000] - loss: 0.046 - mean_absolute_error: 0.739 - mean_q: 0.896\n",
            "\n",
            "Interval 2 (10000 steps performed)\n",
            "10000/10000 [==============================] - 52s 5ms/step - reward: -0.0554\n",
            "2630 episodes - episode_reward: -0.211 [-1.000, 1.000] - loss: 0.044 - mean_absolute_error: 0.863 - mean_q: 1.043\n",
            "\n",
            "Interval 3 (20000 steps performed)\n",
            "10000/10000 [==============================] - 52s 5ms/step - reward: -0.0538\n",
            "2640 episodes - episode_reward: -0.204 [-1.000, 1.000] - loss: 0.045 - mean_absolute_error: 0.869 - mean_q: 1.045\n",
            "\n",
            "Interval 4 (30000 steps performed)\n",
            "10000/10000 [==============================] - 52s 5ms/step - reward: -0.0547\n",
            "2635 episodes - episode_reward: -0.208 [-1.000, 1.000] - loss: 0.045 - mean_absolute_error: 0.873 - mean_q: 1.050\n",
            "\n",
            "Interval 5 (40000 steps performed)\n",
            "10000/10000 [==============================] - 52s 5ms/step - reward: -0.0603\n",
            "done, took 259.720 seconds\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBo9FsQW7GXB",
        "outputId": "97ad7e0a-4c63-446c-8bda-7ce7c3039aa6"
      },
      "source": [
        "import rl.callbacks\r\n",
        " \r\n",
        "# ログを記録するためのクラスの定義\r\n",
        "class EpisodeLogger(rl.callbacks.Callback):\r\n",
        "    def __init__(self):\r\n",
        "        self.rewards = {}\r\n",
        "    def on_episode_begin(self, episode, logs):\r\n",
        "        self.rewards[episode] = []\r\n",
        "    def on_step_end(self, step, logs):\r\n",
        "        episode = logs['episode']\r\n",
        "        self.rewards[episode].append(logs['reward'])\r\n",
        " \r\n",
        "episode_logger = EpisodeLogger()\r\n",
        "nb_episodes = 100\r\n",
        "dqn.test(env, nb_episodes=nb_episodes, visualize=False, callbacks=[episode_logger])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing for 100 episodes ...\n",
            "Episode 1: reward: 1.000, steps: 4\n",
            "Episode 2: reward: 1.000, steps: 4\n",
            "Episode 3: reward: 1.000, steps: 4\n",
            "Episode 4: reward: 1.000, steps: 4\n",
            "Episode 5: reward: 1.000, steps: 5\n",
            "Episode 6: reward: 1.000, steps: 3\n",
            "Episode 7: reward: 1.000, steps: 4\n",
            "Episode 8: reward: 1.000, steps: 4\n",
            "Episode 9: reward: 1.000, steps: 4\n",
            "Episode 10: reward: 1.000, steps: 3\n",
            "Episode 11: reward: 1.000, steps: 5\n",
            "Episode 12: reward: 1.000, steps: 3\n",
            "Episode 13: reward: 1.000, steps: 4\n",
            "Episode 14: reward: 1.000, steps: 4\n",
            "Episode 15: reward: 1.000, steps: 3\n",
            "Episode 16: reward: 1.000, steps: 4\n",
            "Episode 17: reward: 1.000, steps: 3\n",
            "Episode 18: reward: 1.000, steps: 3\n",
            "Episode 19: reward: 1.000, steps: 4\n",
            "Episode 20: reward: 1.000, steps: 4\n",
            "Episode 21: reward: 1.000, steps: 3\n",
            "Episode 22: reward: 1.000, steps: 3\n",
            "Episode 23: reward: 1.000, steps: 5\n",
            "Episode 24: reward: 1.000, steps: 4\n",
            "Episode 25: reward: 1.000, steps: 5\n",
            "Episode 26: reward: 1.000, steps: 4\n",
            "Episode 27: reward: 1.000, steps: 3\n",
            "Episode 28: reward: 1.000, steps: 4\n",
            "Episode 29: reward: 1.000, steps: 4\n",
            "Episode 30: reward: 1.000, steps: 3\n",
            "Episode 31: reward: 1.000, steps: 3\n",
            "Episode 32: reward: 1.000, steps: 3\n",
            "Episode 33: reward: 1.000, steps: 3\n",
            "Episode 34: reward: 1.000, steps: 4\n",
            "Episode 35: reward: 1.000, steps: 4\n",
            "Episode 36: reward: 1.000, steps: 4\n",
            "Episode 37: reward: 1.000, steps: 4\n",
            "Episode 38: reward: 1.000, steps: 5\n",
            "Episode 39: reward: 1.000, steps: 4\n",
            "Episode 40: reward: 1.000, steps: 4\n",
            "Episode 41: reward: 1.000, steps: 5\n",
            "Episode 42: reward: 1.000, steps: 3\n",
            "Episode 43: reward: 1.000, steps: 5\n",
            "Episode 44: reward: 1.000, steps: 4\n",
            "Episode 45: reward: 1.000, steps: 3\n",
            "Episode 46: reward: 1.000, steps: 4\n",
            "Episode 47: reward: 1.000, steps: 3\n",
            "Episode 48: reward: 1.000, steps: 5\n",
            "Episode 49: reward: 1.000, steps: 4\n",
            "Episode 50: reward: 1.000, steps: 4\n",
            "Episode 51: reward: 1.000, steps: 5\n",
            "Episode 52: reward: 1.000, steps: 3\n",
            "Episode 53: reward: 1.000, steps: 3\n",
            "Episode 54: reward: 1.000, steps: 3\n",
            "Episode 55: reward: 1.000, steps: 4\n",
            "Episode 56: reward: 1.000, steps: 3\n",
            "Episode 57: reward: 1.000, steps: 5\n",
            "Episode 58: reward: 1.000, steps: 3\n",
            "Episode 59: reward: 1.000, steps: 3\n",
            "Episode 60: reward: 1.000, steps: 5\n",
            "Episode 61: reward: 1.000, steps: 5\n",
            "Episode 62: reward: 1.000, steps: 4\n",
            "Episode 63: reward: 1.000, steps: 5\n",
            "Episode 64: reward: 1.000, steps: 3\n",
            "Episode 65: reward: 1.000, steps: 4\n",
            "Episode 66: reward: 1.000, steps: 4\n",
            "Episode 67: reward: 1.000, steps: 4\n",
            "Episode 68: reward: 1.000, steps: 3\n",
            "Episode 69: reward: 1.000, steps: 3\n",
            "Episode 70: reward: 1.000, steps: 4\n",
            "Episode 71: reward: 1.000, steps: 3\n",
            "Episode 72: reward: 1.000, steps: 3\n",
            "Episode 73: reward: 1.000, steps: 3\n",
            "Episode 74: reward: 1.000, steps: 3\n",
            "Episode 75: reward: 1.000, steps: 4\n",
            "Episode 76: reward: 1.000, steps: 4\n",
            "Episode 77: reward: 1.000, steps: 3\n",
            "Episode 78: reward: 1.000, steps: 3\n",
            "Episode 79: reward: 1.000, steps: 5\n",
            "Episode 80: reward: 1.000, steps: 4\n",
            "Episode 81: reward: 1.000, steps: 3\n",
            "Episode 82: reward: 1.000, steps: 4\n",
            "Episode 83: reward: 1.000, steps: 5\n",
            "Episode 84: reward: 1.000, steps: 3\n",
            "Episode 85: reward: 1.000, steps: 4\n",
            "Episode 86: reward: 1.000, steps: 5\n",
            "Episode 87: reward: 1.000, steps: 3\n",
            "Episode 88: reward: 1.000, steps: 3\n",
            "Episode 89: reward: 1.000, steps: 4\n",
            "Episode 90: reward: 1.000, steps: 4\n",
            "Episode 91: reward: 1.000, steps: 4\n",
            "Episode 92: reward: 1.000, steps: 5\n",
            "Episode 93: reward: 1.000, steps: 4\n",
            "Episode 94: reward: 1.000, steps: 4\n",
            "Episode 95: reward: 1.000, steps: 4\n",
            "Episode 96: reward: 1.000, steps: 3\n",
            "Episode 97: reward: 1.000, steps: 5\n",
            "Episode 98: reward: 1.000, steps: 4\n",
            "Episode 99: reward: 1.000, steps: 3\n",
            "Episode 100: reward: 1.000, steps: 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9f8d071550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qEMcGEexHvk"
      },
      "source": [
        "import math\r\n",
        "import gym\r\n",
        "from gym import spaces, logger\r\n",
        "from gym.utils import seeding\r\n",
        "import numpy as np\r\n",
        "import copy\r\n",
        "import random\r\n",
        "\r\n",
        "class TicTacToe(gym.core.Env):\r\n",
        "    def __init__(self):\r\n",
        "        self.n_action = 9\r\n",
        "        self.board = [0] * self.n_action\r\n",
        "        self.action_space = gym.spaces.Discrete(self.n_action) # actionの取りうる値\r\n",
        "        self.observation_space = gym.spaces.Box(low=-1, high =1, shape=(self.n_action,)) \r\n",
        "        self.result = []\r\n",
        "\r\n",
        "    def step(self, action):\r\n",
        "      self.board, end_flg, reward = self.get_input(self.board, action)\r\n",
        "      done = end_flg\r\n",
        "      info = {}\r\n",
        "\r\n",
        "      return self.board, reward, done, info\r\n",
        "\r\n",
        "    def get_input(self, board, action):\r\n",
        "      end_flg = 0\r\n",
        "      reward = 0\r\n",
        "      #AI#\r\n",
        "      space = [i for i, x in enumerate(board) if x == 0 ]\r\n",
        "      if action in space:\r\n",
        "        flg = 1\r\n",
        "        board[action] = flg\r\n",
        "        end_flg = self.judge(board,flg)\r\n",
        "        if end_flg == 1:\r\n",
        "          reward = 1\r\n",
        "          print(\"Lose\")\r\n",
        "          self.result.append(reward)\r\n",
        "      #human#\r\n",
        "        else:\r\n",
        "          print('\\n')\r\n",
        "          print(str(board[0]) + '|' + str(board[1]) + '|' + str(board[2]))\r\n",
        "          print(\"-----\")\r\n",
        "          print(str(board[3]) + '|' + str(board[4]) + '|' + str(board[5]))\r\n",
        "          print(\"-----\")\r\n",
        "          print(str(board[6]) + '|' + str(board[7]) + '|' + str(board[8]))\r\n",
        "          print('\\n')\r\n",
        "          space = [i for i, x in enumerate(board) if x == 0 ]\r\n",
        "          print(space)\r\n",
        "          human = input()\r\n",
        "          flg = -1\r\n",
        "          board[int(human)] = flg\r\n",
        "          end_flg = self.judge(board,flg)\r\n",
        "          if end_flg == 1:\r\n",
        "            reward = -1\r\n",
        "            print(\"Win\")\r\n",
        "      else:\r\n",
        "        end_flg = 1\r\n",
        "        reward = -1\r\n",
        "        self.result.append(reward)\r\n",
        "\r\n",
        "      return board, end_flg, reward\r\n",
        "\r\n",
        "    def judge(self, board, flg):\r\n",
        "      end_flg = 0\r\n",
        "      first_list = [0, 3, 6, 0, 1, 2, 0, 2]\r\n",
        "      second_list = [1, 4, 7, 3, 4, 5, 4, 4]\r\n",
        "      third_list = [2, 5, 8, 6, 7, 8, 8, 6]\r\n",
        "      for first, second, third in zip(first_list, second_list, third_list):\r\n",
        "        if board[first] ==flg and board[first] == board[second] and board[first] == board[third]:\r\n",
        "          end_flg = 1\r\n",
        "          break\r\n",
        "      space = [i for i, x in enumerate(board) if x == 0 ]\r\n",
        "      if len(space) == 0:\r\n",
        "        end_flg = 1\r\n",
        "        reward = -1\r\n",
        "\r\n",
        "      return end_flg\r\n",
        "    \r\n",
        "    def reset(self):\r\n",
        "        self.board = [0] * self.n_action\r\n",
        "        return self.board\r\n",
        "\r\n",
        "    def render(self, mode):\r\n",
        "        pass\r\n",
        "\r\n",
        "    def close(self):\r\n",
        "        pass\r\n",
        "\r\n",
        "    def seed(self):\r\n",
        "        pass"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QL7C-OFLxsp-",
        "outputId": "8fd46213-9acb-4827-d2b4-82b661088f94"
      },
      "source": [
        "env2 = TicTacToe()\r\n",
        "import rl.callbacks\r\n",
        " \r\n",
        "nb_episodes = 1\r\n",
        "dqn.test(env2, nb_episodes=nb_episodes, visualize=False)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing for 1 episodes ...\n",
            "\n",
            "\n",
            "0|0|1\n",
            "-----\n",
            "0|0|0\n",
            "-----\n",
            "0|0|0\n",
            "\n",
            "\n",
            "[0, 1, 3, 4, 5, 6, 7, 8]\n",
            "5\n",
            "\n",
            "\n",
            "0|0|1\n",
            "-----\n",
            "0|0|-1\n",
            "-----\n",
            "0|1|0\n",
            "\n",
            "\n",
            "[0, 1, 3, 4, 6, 8]\n",
            "4\n",
            "\n",
            "\n",
            "0|0|1\n",
            "-----\n",
            "1|-1|-1\n",
            "-----\n",
            "0|1|0\n",
            "\n",
            "\n",
            "[0, 1, 6, 8]\n",
            "0\n",
            "\n",
            "\n",
            "-1|0|1\n",
            "-----\n",
            "1|-1|-1\n",
            "-----\n",
            "0|1|1\n",
            "\n",
            "\n",
            "[1, 6]\n",
            "6\n",
            "Lose\n",
            "Episode 1: reward: 1.000, steps: 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9f616f5ba8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HB0yxuT2iKZB",
        "outputId": "51d20720-528a-4f89-aab4-ef225cc35122"
      },
      "source": [
        "mass = 5\r\n",
        "for i in range(5):\r\n",
        "  print(i)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEFEEjrp-Qgq",
        "outputId": "3265b6bb-6961-4bd3-8d89-ac5c42c41cba"
      },
      "source": [
        "mass = 10\r\n",
        "moku = 5\r\n",
        "board =[[0,0,0,0,0,0,0,0,0,0],[1,1,0,1,1,1,1,1,1,1,],[0,0,0,0,1,0,0,0,0,0],[0,0,0,0,1,0,0,0,0,0],[0,0,0,0,1,0,0,0,0,0],[0,0,0,0,1,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0,0,0],[1,1,1,1,1,1,1,1,1,1]]\r\n",
        "flg = 1\r\n",
        "end_flg = 0\r\n",
        "reward = 0\r\n",
        "for i in range(mass-moku):\r\n",
        "  for j in range(mass-moku):\r\n",
        "    for k in range(mass-moku):\r\n",
        "      if ((board[i][j+k] == board[i+1][j+k] == board[i+2][j+k] == board[i+3][j+k] == board[i+4][j+k] == flg) or\r\n",
        "         (board[i+k][j] == board[i+k][j+1] == board[i+k][j+2] == board[i+k][j+3] == board[i+k][j+4] == flg)):\r\n",
        "        end_flg = 1\r\n",
        "        reward = 1\r\n",
        "        print(i,\":\",j,\":\",k)\r\n",
        "        break\r\n",
        "     # break\r\n",
        "    if ((board[i][j] == board[i+1][j+1] == board[i+2][j+2] == board[i+3][j+3] == board[i+4][j+4] == flg) or\r\n",
        "      (board[i][j+4] == board[i+1][j+3] == board[i+2][j+2] == board[i+3][j+1] == board[i+4][j] == flg)):\r\n",
        "      end_flg = 1\r\n",
        "      reward = 1\r\n",
        "      print(i,\":\",j)\r\n",
        "      break\r\n",
        "    break\r\n",
        "\r\n",
        "print(end_flg)\r\n",
        "print(reward)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 : 0 : 4\n",
            "1\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y20aaxVdnZla",
        "outputId": "8af0b026-567a-4724-b98e-01aec2da548f"
      },
      "source": [
        "mass = 10\r\n",
        "moku = 5\r\n",
        "board =[[0,0,0,0,0,0,0,0,0,0],\r\n",
        "        [1,1,-1,-1,-1,-1,1,-1,1,1],\r\n",
        "        [0,0,0,0,1,0,0,0,0,0],\r\n",
        "        [0,0,0,0,1,0,0,0,0,0],\r\n",
        "        [0,0,0,-1,1,0,0,0,0,0],\r\n",
        "        [0,0,1,0,-1,0,0,0,0,0],\r\n",
        "        [0,-1,0,0,-1,0,0,0,0,0],\r\n",
        "        [1,0,0,0,0,0,0,0,0,0],\r\n",
        "        [0,0,0,0,0,0,0,0,0,0],\r\n",
        "        [-1,-1,-1,1,-1,1,-1,1,1,1]]\r\n",
        "flg = 1\r\n",
        "end_flg = 0\r\n",
        "reward = 0\r\n",
        "score = []\r\n",
        "for i in range(mass-moku+1):\r\n",
        "  for j in range(mass-moku+1):\r\n",
        "    for k in range(mass-moku):\r\n",
        "      score_r = board[i][j+k] + board[i+1][j+k] + board[i+2][j+k] + board[i+3][j+k] + board[i+4][j+k]\r\n",
        "      score.append(score_r)\r\n",
        "      score_c = board[i+k][j] + board[i+k][j+1] + board[i+k][j+2] + board[i+k][j+3] + board[i+k][j+4]\r\n",
        "      score.append(score_c)\r\n",
        "    score_dl = board[i][j] + board[i+1][j+1] + board[i+2][j+2] + board[i+3][j+3] + board[i+4][j+4]\r\n",
        "    score.append(score_dl)\r\n",
        "    score_dr = board[i][j+4] + board[i+1][j+3] + board[i+2][j+2] + board[i+3][j+1] + board[i+4][j]\r\n",
        "    score.append(score_dr)\r\n",
        "    if abs(max(score)) == 5:\r\n",
        "      end_flg = 1\r\n",
        "      print(i+k,\":\",j+k)\r\n",
        "    #break\r\n",
        "#    break\r\n",
        "\r\n",
        "reward = max(score)\r\n",
        "\r\n",
        "print(end_flg)\r\n",
        "print(reward)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkOhT1k3jV0L"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}